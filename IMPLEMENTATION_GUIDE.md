# ğŸš€ jinno-ai GitHub ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå®Ÿè£…ã‚¬ã‚¤ãƒ‰ï¼ˆè©³ç´°ç‰ˆï¼‰

## ğŸ“‹ æ¦‚è¦

ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€jinno-aiã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§é­…åŠ›çš„ãªAIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®**å…·ä½“çš„ãªå®Ÿè£…æ‰‹é †**ã‚’ã€ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã§è©³ç´°ã«èª¬æ˜ã—ã¾ã™ã€‚

### ğŸ¯ ã“ã®ã‚¬ã‚¤ãƒ‰ã§é”æˆã§ãã‚‹ã“ã¨

- ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªGitHubãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã®æ§‹ç¯‰
- 6ã¤ã®é«˜å“è³ªAIãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒªãƒã‚¸ãƒˆãƒªã®ä½œæˆ
- æŠ€è¡“çš„ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆã®ç†è§£
- æ¡ç”¨æ‹…å½“è€…ã«éŸ¿ããƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®å®Œæˆ

### ğŸ“Š å…¨ä½“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

| Phase | å†…å®¹ | æ‰€è¦æ™‚é–“ | å„ªå…ˆåº¦ |
|-------|------|----------|--------|
| Phase 1 | Profile READMEä½œæˆ | 1-2æ™‚é–“ | ğŸ”´ æœ€å„ªå…ˆ |
| Phase 2 | Enterprise RAG System | 2-3æ—¥ | ğŸ”´ æœ€å„ªå…ˆ |
| Phase 3 | LLM Agent Framework | 2-3æ—¥ | ğŸŸ¡ é«˜ |
| Phase 4 | è¿½åŠ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼ˆ4ã¤ï¼‰ | å„1-2æ—¥ | ğŸŸ¢ ä¸­ |
| Phase 5-9 | å“è³ªå‘ä¸Šãƒ»ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ | ç¶™ç¶šçš„ | ğŸŸ¢ ä¸­ |

---

## âœ… Phase 1: Profile READMEä½œæˆï¼ˆæœ€å„ªå…ˆï¼‰

### ğŸ¯ ç›®æ¨™

GitHubãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒšãƒ¼ã‚¸ã«è¡¨ç¤ºã•ã‚Œã‚‹é­…åŠ›çš„ãªREADMEã‚’ä½œæˆã—ã€è¨ªå•è€…ã«å¼·ã„ç¬¬ä¸€å°è±¡ã‚’ä¸ãˆã‚‹ã€‚

### Step 1-1: Profile READMEãƒªãƒã‚¸ãƒˆãƒªã®ä½œæˆ

#### 1.1.1 GitHubã«ãƒ­ã‚°ã‚¤ãƒ³

1. ãƒ–ãƒ©ã‚¦ã‚¶ã§ [https://github.com](https://github.com) ã«ã‚¢ã‚¯ã‚»ã‚¹
2. å³ä¸Šã®ã€ŒSign inã€ã‚’ã‚¯ãƒªãƒƒã‚¯
3. ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³

#### 1.1.2 æ–°è¦ãƒªãƒã‚¸ãƒˆãƒªä½œæˆç”»é¢ã¸ç§»å‹•

1. å³ä¸Šã®ã€Œ+ã€ã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
2. ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã‹ã‚‰ã€ŒNew repositoryã€ã‚’é¸æŠ

#### 1.1.3 ãƒªãƒã‚¸ãƒˆãƒªè¨­å®š

ä»¥ä¸‹ã®è¨­å®šã§æ–°è¦ãƒªãƒã‚¸ãƒˆãƒªã‚’ä½œæˆï¼š

| é …ç›® | è¨­å®šå€¤ | èª¬æ˜ |
|------|--------|------|
| Repository name | `jinno-ai` | âš ï¸ **å¿…ãšãƒ¦ãƒ¼ã‚¶ãƒ¼åã¨å®Œå…¨ä¸€è‡´ã•ã›ã‚‹** |
| Description | `My GitHub Profile` | ä»»æ„ã®èª¬æ˜æ–‡ |
| Visibility | `Public` | å…¬é–‹è¨­å®šï¼ˆå¿…é ˆï¼‰ |
| Initialize | âœ… Add a README file | ãƒã‚§ãƒƒã‚¯ã‚’å…¥ã‚Œã‚‹ |

```text
âš ï¸ é‡è¦: ãƒªãƒã‚¸ãƒˆãƒªåãŒãƒ¦ãƒ¼ã‚¶ãƒ¼åã¨ä¸€è‡´ã—ãªã„ã¨ã€Profile READMEã¨ã—ã¦èªè­˜ã•ã‚Œã¾ã›ã‚“ï¼
```

#### 1.1.4 ä½œæˆå®Œäº†ã®ç¢ºèª

ã€ŒCreate repositoryã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯å¾Œã€ä»¥ä¸‹ã‚’ç¢ºèªï¼š
- ãƒªãƒã‚¸ãƒˆãƒªãƒšãƒ¼ã‚¸ã«ã€Œjinno-ai/jinno-ai is a âœ¨ special âœ¨ repositoryã€ã¨è¡¨ç¤ºã•ã‚Œã‚‹
- ã“ã‚ŒãŒè¡¨ç¤ºã•ã‚Œã‚Œã°ã€Profile READMEã¨ã—ã¦æ­£ã—ãèªè­˜ã•ã‚Œã¦ã„ã¾ã™

### Step 1-2: README.mdã®æ›´æ–°

#### 1.2.1 ç·¨é›†ç”»é¢ã‚’é–‹ã

1. ä½œæˆã—ãŸãƒªãƒã‚¸ãƒˆãƒªã® `README.md` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒƒã‚¯
2. å³ä¸Šã®é‰›ç­†ã‚¢ã‚¤ã‚³ãƒ³ï¼ˆEdit this fileï¼‰ã‚’ã‚¯ãƒªãƒƒã‚¯

#### 1.2.2 ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è²¼ã‚Šä»˜ã‘

1. ã“ã®ã‚­ãƒƒãƒˆã«å«ã¾ã‚Œã‚‹ `jinno-ai-profile-README.md` ã‚’é–‹ã
2. å…¨å†…å®¹ã‚’ã‚³ãƒ”ãƒ¼ï¼ˆCtrl+A â†’ Ctrl+Cï¼‰
3. GitHubç·¨é›†ç”»é¢ã«è²¼ã‚Šä»˜ã‘ï¼ˆCtrl+Vï¼‰

#### 1.2.3 ã‚³ãƒŸãƒƒãƒˆ

1. ç”»é¢ä¸‹éƒ¨ã®ã€ŒCommit changesã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¸ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
2. ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: `Update profile README with professional content`
3. ã€ŒCommit changesã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯

### Step 1-3: ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºï¼ˆå¿…é ˆï¼‰

ä»¥ä¸‹ã®ç®‡æ‰€ã‚’å®Ÿéš›ã®æƒ…å ±ã«å¤‰æ›´ã—ã¦ãã ã•ã„ï¼š

```markdown
# å¤‰æ›´å¿…é ˆç®‡æ‰€ä¸€è¦§

## SNSãƒªãƒ³ã‚¯ï¼ˆå®Ÿéš›ã®URLã«å¤‰æ›´ï¼‰
- LinkedIn: https://linkedin.com/in/YOUR_LINKEDIN
- Twitter: https://twitter.com/YOUR_TWITTER
- Medium: https://medium.com/@YOUR_MEDIUM
- Portfolio: https://YOUR_PORTFOLIO_URL
- Email: YOUR_EMAIL@example.com

## çµ±è¨ˆæƒ…å ±ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’å¤‰æ›´ï¼‰
- github-readme-stats ã®URLå†… `username=jinno-ai` ã‚’è‡ªåˆ†ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åã«
- github-readme-streak-stats ã®URLå†… `user=jinno-ai` ã‚’è‡ªåˆ†ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åã«
```

### Step 1-4: å‹•ä½œç¢ºèª

1. GitHubãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒšãƒ¼ã‚¸ï¼ˆ`https://github.com/jinno-ai`ï¼‰ã«ã‚¢ã‚¯ã‚»ã‚¹
2. ä½œæˆã—ãŸREADMEãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
3. å„ãƒãƒƒã‚¸ã€çµ±è¨ˆæƒ…å ±ãŒæ­£ã—ãè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª

```text
âœ… ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ:
â–¡ ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãŒå‹•ä½œã—ã¦ã„ã‚‹
â–¡ Tech Stackã®ãƒãƒƒã‚¸ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹
â–¡ GitHub StatsãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹
â–¡ SNSãƒªãƒ³ã‚¯ãŒæ­£ã—ãæ©Ÿèƒ½ã™ã‚‹
```

---

## âœ… Phase 2: Enterprise RAG System ãƒªãƒã‚¸ãƒˆãƒªã®ä½œæˆ

### ğŸ¯ ç›®æ¨™

æœ¬æ ¼çš„ãªRAGï¼ˆRetrieval-Augmented Generationï¼‰ã‚·ã‚¹ãƒ†ãƒ ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ä½œæˆã—ã€AIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¨ã—ã¦ã®æŠ€è¡“åŠ›ã‚’ç¤ºã™ã€‚

### ğŸ“ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Enterprise RAG System                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   User      â”‚â”€â”€â”€â–¶â”‚  FastAPI    â”‚â”€â”€â”€â–¶â”‚  Query      â”‚        â”‚
â”‚  â”‚   Query     â”‚    â”‚  Endpoint   â”‚    â”‚  Processor  â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                               â”‚                â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                     â”‚                         â–¼            â”‚   â”‚
â”‚                     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚                     â”‚  â”‚  Semantic   â”‚  â”‚   BM25      â”‚   â”‚   â”‚
â”‚                     â”‚  â”‚  Search     â”‚  â”‚   Search    â”‚   â”‚   â”‚
â”‚                     â”‚  â”‚  (Vector)   â”‚  â”‚  (Keyword)  â”‚   â”‚   â”‚
â”‚                     â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚                     â”‚         â”‚                â”‚          â”‚   â”‚
â”‚                     â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚   â”‚
â”‚                     â”‚                  â–¼                  â”‚   â”‚
â”‚                     â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚   â”‚
â”‚                     â”‚         â”‚  RRF Fusion â”‚             â”‚   â”‚
â”‚                     â”‚         â”‚  (Hybrid)   â”‚             â”‚   â”‚
â”‚                     â”‚         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜             â”‚   â”‚
â”‚                     â”‚                â”‚                    â”‚   â”‚
â”‚                     â”‚    Retrieval   â”‚   Layer            â”‚   â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                      â–¼                        â”‚
â”‚                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚                            â”‚  Re-Ranker  â”‚                    â”‚
â”‚                            â”‚  (Cross-    â”‚                    â”‚
â”‚                            â”‚   Encoder)  â”‚                    â”‚
â”‚                            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                   â–¼                           â”‚
â”‚                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚                            â”‚  Context    â”‚                    â”‚
â”‚                            â”‚ Compressor  â”‚                    â”‚
â”‚                            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                   â–¼                           â”‚
â”‚                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚                            â”‚    LLM      â”‚                    â”‚
â”‚                            â”‚  (GPT-4/    â”‚                    â”‚
â”‚                            â”‚   Claude)   â”‚                    â”‚
â”‚                            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                   â–¼                           â”‚
â”‚                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚                            â”‚  Response   â”‚                    â”‚
â”‚                            â”‚  + Sources  â”‚                    â”‚
â”‚                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“Š æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯è©³ç´°

| ãƒ¬ã‚¤ãƒ¤ãƒ¼ | æŠ€è¡“ | å½¹å‰² | é¸å®šç†ç”± |
|----------|------|------|----------|
| **API** | FastAPI | RESTful API | é«˜é€Ÿã€å‹å®‰å…¨ã€è‡ªå‹•ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ |
| **UI** | Streamlit | ãƒ‡ãƒ¢ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ | è¿…é€Ÿãªãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°ã€Pythonãƒã‚¤ãƒ†ã‚£ãƒ– |
| **Embedding** | OpenAI Ada-002 | ãƒ™ã‚¯ãƒˆãƒ«åŒ– | é«˜å“è³ªã€1536æ¬¡å…ƒã€å¤šè¨€èªå¯¾å¿œ |
| **Vector DB** | Pinecone | é¡ä¼¼æ¤œç´¢ | ãƒãƒãƒ¼ã‚¸ãƒ‰ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã€ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· |
| **Keyword Search** | BM25 | ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ | è»½é‡ã€é«˜é€Ÿã€å°‚é–€ç”¨èªã«å¼·ã„ |
| **Re-Ranker** | Cross-Encoder | ç²¾åº¦å‘ä¸Š | æ–‡è„ˆç†è§£ã€é–¢é€£æ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° |
| **LLM** | GPT-4 / Claude | å›ç­”ç”Ÿæˆ | é«˜å“è³ªãªè‡ªç„¶è¨€èªç”Ÿæˆ |
| **Cache** | Redis | å¿œç­”ã‚­ãƒ£ãƒƒã‚·ãƒ¥ | ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã€TTLç®¡ç† |
| **Monitoring** | LangSmith | ãƒ‡ãƒãƒƒã‚°ãƒ»ç›£è¦– | LangChainå…¬å¼ã€è©³ç´°ãƒˆãƒ¬ãƒ¼ã‚¹ |

### Step 2-1: ãƒªãƒã‚¸ãƒˆãƒªä½œæˆ

#### 2.1.1 GitHubä¸Šã§æ–°è¦ãƒªãƒã‚¸ãƒˆãƒªã‚’ä½œæˆ

1. GitHubã«ãƒ­ã‚°ã‚¤ãƒ³
2. å³ä¸Šã®ã€Œ+ã€â†’ã€ŒNew repositoryã€ã‚’ã‚¯ãƒªãƒƒã‚¯
3. ä»¥ä¸‹ã®è¨­å®šã§ä½œæˆï¼š

| é …ç›® | è¨­å®šå€¤ |
|------|--------|
| Repository name | `enterprise-rag-system` |
| Description | `Production-grade RAG pipeline for enterprise knowledge bases` |
| Visibility | `Public` |
| Initialize | âœ… Add a README file |
| .gitignore | `Python` ã‚’é¸æŠ |
| License | `MIT License` ã‚’é¸æŠ |

4. ã€ŒCreate repositoryã€ã‚’ã‚¯ãƒªãƒƒã‚¯

### Step 2-2: ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

#### 2.2.1 ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³

```bash
# ãƒ›ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¾ãŸã¯ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•
cd ~/projects  # ã¾ãŸã¯ä»»æ„ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

# ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/jinno-ai/enterprise-rag-system.git

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•
cd enterprise-rag-system
```

#### 2.2.2 Pythonä»®æƒ³ç’°å¢ƒã®ä½œæˆï¼ˆæ¨å¥¨ï¼‰

```bash
# Pythonä»®æƒ³ç’°å¢ƒã‚’ä½œæˆ
python -m venv venv

# ä»®æƒ³ç’°å¢ƒã‚’æœ‰åŠ¹åŒ–
# Linux/Mac:
source venv/bin/activate
# Windows:
# venv\Scripts\activate

# pipã‚’ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰
pip install --upgrade pip
```

### Step 2-3: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®ä½œæˆ

#### 2.3.1 ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§å®Œå…¨ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ä½œæˆï¼š

```bash
# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ§‹é€ 
mkdir -p app/core
mkdir -p app/api/routes
mkdir -p app/services
mkdir -p app/utils
mkdir -p app/models

# UIé–¢é€£
mkdir -p ui/components
mkdir -p ui/styles

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ»ãƒ„ãƒ¼ãƒ«
mkdir -p scripts

# ãƒ†ã‚¹ãƒˆæ§‹é€ 
mkdir -p tests/unit
mkdir -p tests/integration
mkdir -p tests/e2e
mkdir -p tests/fixtures

# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
mkdir -p docs/images
mkdir -p docs/api

# Jupyter Notebooks
mkdir -p notebooks

# ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆè¨­å®š
mkdir -p deployment/kubernetes
mkdir -p deployment/terraform
mkdir -p deployment/docker

# ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
mkdir -p data/documents
mkdir -p data/processed
mkdir -p data/evaluation

# GitHub Actions
mkdir -p .github/workflows
```

#### 2.3.2 Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åˆæœŸåŒ–ãƒ•ã‚¡ã‚¤ãƒ«

```bash
# __init__.py ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆPythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨ã—ã¦èªè­˜ã•ã›ã‚‹ï¼‰
touch app/__init__.py
touch app/core/__init__.py
touch app/api/__init__.py
touch app/api/routes/__init__.py
touch app/services/__init__.py
touch app/utils/__init__.py
touch app/models/__init__.py
touch tests/__init__.py
touch tests/unit/__init__.py
touch tests/integration/__init__.py
```

#### 2.3.3 æœ€çµ‚çš„ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

```text
enterprise-rag-system/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ test.yml           # è‡ªå‹•ãƒ†ã‚¹ãƒˆ
â”‚       â””â”€â”€ lint.yml           # ã‚³ãƒ¼ãƒ‰å“è³ªãƒã‚§ãƒƒã‚¯
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                # FastAPIã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
â”‚   â”œâ”€â”€ config.py              # è¨­å®šç®¡ç†
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ embeddings.py      # Embeddingãƒ¢ãƒ‡ãƒ«
â”‚   â”‚   â”œâ”€â”€ retriever.py       # æ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯
â”‚   â”‚   â”œâ”€â”€ reranker.py        # Re-ranking
â”‚   â”‚   â””â”€â”€ generator.py       # LLMå›ç­”ç”Ÿæˆ
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ deps.py            # ä¾å­˜æ€§æ³¨å…¥
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ query.py       # ã‚¯ã‚¨ãƒªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
â”‚   â”‚       â”œâ”€â”€ ingest.py      # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå–ã‚Šè¾¼ã¿
â”‚   â”‚       â””â”€â”€ health.py      # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ document_processor.py  # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†
â”‚   â”‚   â”œâ”€â”€ vector_store.py        # ãƒ™ã‚¯ãƒˆãƒ«DBæ“ä½œ
â”‚   â”‚   â””â”€â”€ cache.py               # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ schemas.py         # Pydanticã‚¹ã‚­ãƒ¼ãƒ
â”‚   â”‚   â””â”€â”€ database.py        # DBãƒ¢ãƒ‡ãƒ«
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logging.py         # ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
â”‚       â””â”€â”€ metrics.py         # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ app.py                 # Streamlitãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒª
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ chat.py            # ãƒãƒ£ãƒƒãƒˆUI
â”‚   â”‚   â””â”€â”€ sidebar.py         # ã‚µã‚¤ãƒ‰ãƒãƒ¼
â”‚   â””â”€â”€ styles/
â”‚       â””â”€â”€ custom.css         # ã‚«ã‚¹ã‚¿ãƒ CSS
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ ingest.py              # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå–ã‚Šè¾¼ã¿ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”‚   â”œâ”€â”€ init_vectordb.py       # ãƒ™ã‚¯ãƒˆãƒ«DBåˆæœŸåŒ–
â”‚   â””â”€â”€ evaluate.py            # è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py            # pytestè¨­å®š
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_embeddings.py
â”‚   â”‚   â””â”€â”€ test_retriever.py
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ test_api.py
â”‚   â””â”€â”€ e2e/
â”‚       â””â”€â”€ test_full_pipeline.py
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ README.md              # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒˆãƒƒãƒ—
â”‚   â”œâ”€â”€ architecture.md        # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è©³ç´°
â”‚   â”œâ”€â”€ api.md                 # APIä»•æ§˜
â”‚   â””â”€â”€ images/
â”‚       â””â”€â”€ demo.gif           # ãƒ‡ãƒ¢GIF
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â””â”€â”€ 02_evaluation.ipynb
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ kubernetes/
â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â””â”€â”€ service.yaml
â”‚   â”œâ”€â”€ terraform/
â”‚   â”‚   â””â”€â”€ main.tf
â”‚   â””â”€â”€ docker/
â”‚       â””â”€â”€ Dockerfile.prod
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ documents/             # å…ƒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
â”‚   â”œâ”€â”€ processed/             # å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
â”‚   â””â”€â”€ evaluation/            # è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
â”œâ”€â”€ .env.example               # ç’°å¢ƒå¤‰æ•°ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
â”œâ”€â”€ .gitignore                 # Gité™¤å¤–è¨­å®š
â”œâ”€â”€ docker-compose.yml         # Docker Composeè¨­å®š
â”œâ”€â”€ Dockerfile                 # APIã‚³ãƒ³ãƒ†ãƒŠ
â”œâ”€â”€ Dockerfile.streamlit       # UIã‚³ãƒ³ãƒ†ãƒŠ
â”œâ”€â”€ requirements.txt           # Pythonä¾å­˜é–¢ä¿‚
â”œâ”€â”€ requirements-dev.txt       # é–‹ç™ºç”¨ä¾å­˜é–¢ä¿‚
â”œâ”€â”€ pyproject.toml             # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š
â”œâ”€â”€ README.md                  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆREADME
â”œâ”€â”€ CONTRIBUTING.md            # ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚¬ã‚¤ãƒ‰
â””â”€â”€ LICENSE                    # MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹
```

### Step 2-4: é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®é…ç½®

#### 2.4.1 README.mdã®é…ç½®

```bash
# ã“ã®ã‚­ãƒƒãƒˆã®READMEã‚’ã‚³ãƒ”ãƒ¼
cp /path/to/jinno-ai-portfolio-kit/enterprise-rag-system-README.md README.md
```

#### 2.4.2 requirements.txtã®é…ç½®

```bash
# ä¾å­˜é–¢ä¿‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
cp /path/to/jinno-ai-portfolio-kit/requirements.txt .
```

#### 2.4.3 docker-compose.ymlã®é…ç½®

```bash
# Docker Composeè¨­å®šã‚’ã‚³ãƒ”ãƒ¼
cp /path/to/jinno-ai-portfolio-kit/docker-compose.yml .
```

#### 2.4.4 ç’°å¢ƒå¤‰æ•°ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ä½œæˆ

`.env.example` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼š

```bash
cat > .env.example << 'EOF'
# ===========================================
# Enterprise RAG System - Environment Variables
# ===========================================

# LLM API Keys
OPENAI_API_KEY=sk-your-openai-api-key-here
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# Vector Database (Pinecone)
PINECONE_API_KEY=your-pinecone-api-key
PINECONE_ENVIRONMENT=us-west1-gcp
PINECONE_INDEX_NAME=enterprise-rag

# Embedding Configuration
EMBEDDING_MODEL=text-embedding-ada-002
EMBEDDING_DIMENSION=1536

# Search Configuration
HYBRID_SEARCH_ALPHA=0.5
TOP_K_RESULTS=5
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-12-v2

# Cache Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
ENABLE_CACHING=true
CACHE_TTL_SECONDS=3600

# Database
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=raguser
POSTGRES_PASSWORD=changeme
POSTGRES_DB=ragdb

# Monitoring
LANGSMITH_API_KEY=your-langsmith-api-key
LANGSMITH_PROJECT=enterprise-rag
ARIZE_API_KEY=your-arize-api-key

# Application
DEBUG=false
LOG_LEVEL=INFO
MAX_WORKERS=4
EOF
```

### Step 2-5: ã‚³ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã®å®Ÿè£…

#### 2.5.1 FastAPIãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆapp/main.pyï¼‰

```python
"""
Enterprise RAG System - Main Application
Production-grade RAG pipeline for enterprise knowledge bases
"""

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager

from app.api.routes import query, ingest, health
from app.config import settings
from app.utils.logging import setup_logging

# Setup logging
logger = setup_logging()


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan management"""
    # Startup
    logger.info("Starting Enterprise RAG System...")
    logger.info(f"Environment: {settings.ENVIRONMENT}")
    yield
    # Shutdown
    logger.info("Shutting down Enterprise RAG System...")


app = FastAPI(
    title="Enterprise RAG System",
    description="Production-grade RAG pipeline for enterprise knowledge bases",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan,
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include routers
app.include_router(health.router, tags=["Health"])
app.include_router(query.router, prefix="/api/v1", tags=["Query"])
app.include_router(ingest.router, prefix="/api/v1", tags=["Ingest"])


@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "message": "Enterprise RAG System API",
        "version": "1.0.0",
        "docs": "/docs",
    }
```

#### 2.5.2 è¨­å®šç®¡ç†ï¼ˆapp/config.pyï¼‰

```python
"""
Configuration management using Pydantic Settings
"""

from pydantic_settings import BaseSettings
from typing import List
from functools import lru_cache


class Settings(BaseSettings):
    """Application settings"""
    
    # Environment
    ENVIRONMENT: str = "development"
    DEBUG: bool = False
    LOG_LEVEL: str = "INFO"
    
    # API Keys
    OPENAI_API_KEY: str = ""
    ANTHROPIC_API_KEY: str = ""
    
    # Vector Database
    PINECONE_API_KEY: str = ""
    PINECONE_ENVIRONMENT: str = "us-west1-gcp"
    PINECONE_INDEX_NAME: str = "enterprise-rag"
    
    # Embedding
    EMBEDDING_MODEL: str = "text-embedding-ada-002"
    EMBEDDING_DIMENSION: int = 1536
    
    # Search
    HYBRID_SEARCH_ALPHA: float = 0.5
    TOP_K_RESULTS: int = 5
    RERANKER_MODEL: str = "cross-encoder/ms-marco-MiniLM-L-12-v2"
    
    # Cache
    REDIS_HOST: str = "localhost"
    REDIS_PORT: int = 6379
    ENABLE_CACHING: bool = True
    CACHE_TTL_SECONDS: int = 3600
    
    # CORS
    ALLOWED_ORIGINS: List[str] = ["http://localhost:3000", "http://localhost:8501"]
    
    class Config:
        env_file = ".env"
        case_sensitive = True


@lru_cache()
def get_settings() -> Settings:
    """Get cached settings instance"""
    return Settings()


settings = get_settings()
```

#### 2.5.3 Pydanticã‚¹ã‚­ãƒ¼ãƒï¼ˆapp/models/schemas.pyï¼‰

```python
"""
Pydantic schemas for request/response validation
"""

from pydantic import BaseModel, Field
from typing import List, Optional
from datetime import datetime


class QueryRequest(BaseModel):
    """Query request schema"""
    query: str = Field(..., min_length=1, max_length=1000, description="User query")
    collection: str = Field(default="default", description="Document collection name")
    top_k: int = Field(default=5, ge=1, le=20, description="Number of results")
    include_sources: bool = Field(default=True, description="Include source documents")
    
    class Config:
        json_schema_extra = {
            "example": {
                "query": "What is our company policy on remote work?",
                "collection": "hr-policies",
                "top_k": 5,
                "include_sources": True
            }
        }


class Source(BaseModel):
    """Source document schema"""
    document: str
    page: Optional[int] = None
    relevance_score: float
    text: str


class QueryResponse(BaseModel):
    """Query response schema"""
    answer: str
    sources: List[Source]
    confidence: float = Field(ge=0, le=1)
    latency_ms: int
    tokens_used: int
    cached: bool = False


class IngestRequest(BaseModel):
    """Document ingestion request"""
    source_path: str
    collection: str = "default"
    chunk_size: int = Field(default=1000, ge=100, le=4000)
    chunk_overlap: int = Field(default=200, ge=0, le=500)


class IngestResponse(BaseModel):
    """Document ingestion response"""
    status: str
    documents_processed: int
    chunks_created: int
    collection: str
    timestamp: datetime


class HealthResponse(BaseModel):
    """Health check response"""
    status: str
    version: str
    services: dict
```

#### 2.5.4 ã‚¯ã‚¨ãƒªAPIãƒ«ãƒ¼ãƒˆï¼ˆapp/api/routes/query.pyï¼‰

```python
"""
Query API endpoints
"""

from fastapi import APIRouter, HTTPException, Depends
from typing import Optional
import time

from app.models.schemas import QueryRequest, QueryResponse, Source
from app.core.retriever import HybridRetriever
from app.core.generator import ResponseGenerator
from app.services.cache import CacheService
from app.config import settings

router = APIRouter()


@router.post("/query", response_model=QueryResponse)
async def query_documents(
    request: QueryRequest,
    retriever: HybridRetriever = Depends(),
    generator: ResponseGenerator = Depends(),
    cache: CacheService = Depends(),
):
    """
    Query the RAG system with a natural language question.
    
    - **query**: The question to ask
    - **collection**: Document collection to search
    - **top_k**: Number of relevant documents to retrieve
    - **include_sources**: Whether to include source citations
    """
    start_time = time.time()
    
    # Check cache
    if settings.ENABLE_CACHING:
        cached_response = await cache.get(request.query, request.collection)
        if cached_response:
            cached_response.cached = True
            return cached_response
    
    try:
        # Retrieve relevant documents
        documents = await retriever.retrieve(
            query=request.query,
            collection=request.collection,
            top_k=request.top_k,
        )
        
        if not documents:
            raise HTTPException(
                status_code=404,
                detail="No relevant documents found for the query"
            )
        
        # Generate response
        response = await generator.generate(
            query=request.query,
            documents=documents,
        )
        
        # Calculate latency
        latency_ms = int((time.time() - start_time) * 1000)
        
        # Build response
        result = QueryResponse(
            answer=response.answer,
            sources=[
                Source(
                    document=doc.metadata.get("source", "Unknown"),
                    page=doc.metadata.get("page"),
                    relevance_score=doc.score,
                    text=doc.content[:500],
                )
                for doc in documents
            ] if request.include_sources else [],
            confidence=response.confidence,
            latency_ms=latency_ms,
            tokens_used=response.tokens_used,
        )
        
        # Cache response
        if settings.ENABLE_CACHING:
            await cache.set(request.query, request.collection, result)
        
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

#### 2.5.5 ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼ˆapp/core/retriever.pyï¼‰

```python
"""
Hybrid Retriever combining semantic and keyword search
"""

from typing import List, Optional
from dataclasses import dataclass
import numpy as np

from langchain_openai import OpenAIEmbeddings
from langchain_community.retrievers import BM25Retriever
from pinecone import Pinecone

from app.config import settings


@dataclass
class RetrievedDocument:
    """Retrieved document with metadata"""
    content: str
    metadata: dict
    score: float


class HybridRetriever:
    """
    Hybrid retriever combining:
    - Semantic search (dense vectors via Pinecone)
    - Keyword search (BM25)
    - Reciprocal Rank Fusion for result merging
    """
    
    def __init__(self):
        self.embeddings = OpenAIEmbeddings(
            model=settings.EMBEDDING_MODEL,
            openai_api_key=settings.OPENAI_API_KEY,
        )
        self.pinecone = Pinecone(api_key=settings.PINECONE_API_KEY)
        self.index = self.pinecone.Index(settings.PINECONE_INDEX_NAME)
        self.alpha = settings.HYBRID_SEARCH_ALPHA  # 0=keyword, 1=semantic
    
    async def retrieve(
        self,
        query: str,
        collection: str,
        top_k: int = 5,
    ) -> List[RetrievedDocument]:
        """
        Retrieve documents using hybrid search
        
        Args:
            query: User query
            collection: Document collection name
            top_k: Number of results to return
            
        Returns:
            List of retrieved documents with scores
        """
        # Get semantic search results
        semantic_results = await self._semantic_search(query, collection, top_k * 2)
        
        # Get keyword search results
        keyword_results = await self._keyword_search(query, collection, top_k * 2)
        
        # Merge using Reciprocal Rank Fusion
        merged_results = self._reciprocal_rank_fusion(
            semantic_results,
            keyword_results,
            k=60,  # RRF constant
        )
        
        return merged_results[:top_k]
    
    async def _semantic_search(
        self,
        query: str,
        collection: str,
        top_k: int,
    ) -> List[RetrievedDocument]:
        """Perform semantic search using vector similarity"""
        # Generate query embedding
        query_embedding = self.embeddings.embed_query(query)
        
        # Search Pinecone
        results = self.index.query(
            vector=query_embedding,
            top_k=top_k,
            namespace=collection,
            include_metadata=True,
        )
        
        return [
            RetrievedDocument(
                content=match.metadata.get("text", ""),
                metadata=match.metadata,
                score=match.score,
            )
            for match in results.matches
        ]
    
    async def _keyword_search(
        self,
        query: str,
        collection: str,
        top_k: int,
    ) -> List[RetrievedDocument]:
        """Perform keyword search using BM25"""
        # Implementation depends on your document store
        # This is a placeholder for BM25 search
        return []
    
    def _reciprocal_rank_fusion(
        self,
        semantic_results: List[RetrievedDocument],
        keyword_results: List[RetrievedDocument],
        k: int = 60,
    ) -> List[RetrievedDocument]:
        """
        Merge results using Reciprocal Rank Fusion
        
        RRF Score = Î£ 1 / (k + rank)
        """
        doc_scores = {}
        
        # Score semantic results
        for rank, doc in enumerate(semantic_results):
            doc_id = doc.metadata.get("id", doc.content[:100])
            rrf_score = self.alpha * (1 / (k + rank + 1))
            doc_scores[doc_id] = doc_scores.get(doc_id, 0) + rrf_score
            doc_scores[f"{doc_id}_doc"] = doc
        
        # Score keyword results
        for rank, doc in enumerate(keyword_results):
            doc_id = doc.metadata.get("id", doc.content[:100])
            rrf_score = (1 - self.alpha) * (1 / (k + rank + 1))
            doc_scores[doc_id] = doc_scores.get(doc_id, 0) + rrf_score
            if f"{doc_id}_doc" not in doc_scores:
                doc_scores[f"{doc_id}_doc"] = doc
        
        # Sort by RRF score
        sorted_docs = sorted(
            [(k, v) for k, v in doc_scores.items() if not k.endswith("_doc")],
            key=lambda x: x[1],
            reverse=True,
        )
        
        return [
            RetrievedDocument(
                content=doc_scores[f"{doc_id}_doc"].content,
                metadata=doc_scores[f"{doc_id}_doc"].metadata,
                score=score,
            )
            for doc_id, score in sorted_docs
        ]
```

### Step 2-6: Streamlit UIï¼ˆui/app.pyï¼‰

```python
"""
Streamlit UI for Enterprise RAG System
"""

import streamlit as st
import requests
from typing import Optional

# Page configuration
st.set_page_config(
    page_title="Enterprise RAG System",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1E88E5;
        margin-bottom: 1rem;
    }
    .source-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .confidence-high { color: #4CAF50; }
    .confidence-medium { color: #FF9800; }
    .confidence-low { color: #F44336; }
</style>
""", unsafe_allow_html=True)

# API configuration
API_BASE_URL = st.secrets.get("API_BASE_URL", "http://localhost:8000")


def query_rag_system(
    query: str,
    collection: str,
    top_k: int,
) -> Optional[dict]:
    """Send query to RAG API"""
    try:
        response = requests.post(
            f"{API_BASE_URL}/api/v1/query",
            json={
                "query": query,
                "collection": collection,
                "top_k": top_k,
                "include_sources": True,
            },
            timeout=30,
        )
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"Error querying API: {str(e)}")
        return None


# Sidebar
with st.sidebar:
    st.image("https://via.placeholder.com/150x50?text=RAG+System", width=150)
    st.markdown("---")
    
    st.subheader("âš™ï¸ Settings")
    collection = st.selectbox(
        "Document Collection",
        ["hr-policies", "technical-docs", "product-specs", "default"],
        index=0,
    )
    
    top_k = st.slider(
        "Number of Sources",
        min_value=1,
        max_value=10,
        value=5,
    )
    
    st.markdown("---")
    st.markdown("### ğŸ“Š System Status")
    st.success("âœ… API Connected")
    st.info("ğŸ“š 3 Collections Available")

# Main content
st.markdown('<p class="main-header">ğŸ¯ Enterprise RAG System</p>', unsafe_allow_html=True)
st.markdown("Ask questions about your enterprise knowledge base")

# Query input
query = st.text_input(
    "Enter your question:",
    placeholder="What is our company policy on remote work?",
    key="query_input",
)

# Search button
if st.button("ğŸ” Search", type="primary") or query:
    if query:
        with st.spinner("Searching knowledge base..."):
            result = query_rag_system(query, collection, top_k)
        
        if result:
            # Display answer
            st.markdown("### ğŸ’¡ Answer")
            st.markdown(result["answer"])
            
            # Display metrics
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                confidence = result["confidence"]
                confidence_class = (
                    "confidence-high" if confidence > 0.8
                    else "confidence-medium" if confidence > 0.5
                    else "confidence-low"
                )
                st.metric("Confidence", f"{confidence:.0%}")
            with col2:
                st.metric("Latency", f"{result['latency_ms']}ms")
            with col3:
                st.metric("Tokens Used", result["tokens_used"])
            with col4:
                st.metric("Cached", "Yes" if result.get("cached") else "No")
            
            # Display sources
            if result["sources"]:
                st.markdown("### ğŸ“š Sources")
                for i, source in enumerate(result["sources"], 1):
                    with st.expander(
                        f"Source {i}: {source['document']} "
                        f"(Relevance: {source['relevance_score']:.2f})"
                    ):
                        st.markdown(f"**Page:** {source.get('page', 'N/A')}")
                        st.markdown(f"**Excerpt:**")
                        st.markdown(f"> {source['text']}")
    else:
        st.warning("Please enter a question")

# Footer
st.markdown("---")
st.markdown(
    "Built with â¤ï¸ using LangChain, Pinecone, and GPT-4 | "
    "[GitHub](https://github.com/jinno-ai/enterprise-rag-system)"
)
```

### Step 2-7: Dockerãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ

#### 2.7.1 APIã‚³ãƒ³ãƒ†ãƒŠï¼ˆDockerfileï¼‰

```dockerfile
# Dockerfile for FastAPI Backend
FROM python:3.10-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for caching
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY app/ ./app/
COPY scripts/ ./scripts/

# Create non-root user
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### 2.7.2 UIã‚³ãƒ³ãƒ†ãƒŠï¼ˆDockerfile.streamlitï¼‰

```dockerfile
# Dockerfile for Streamlit UI
FROM python:3.10-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .
RUN pip install --no-cache-dir streamlit requests

# Copy UI code
COPY ui/ ./ui/

# Create non-root user
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Expose port
EXPOSE 8501

# Run Streamlit
CMD ["streamlit", "run", "ui/app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

### Step 2-8: GitHub Actionsã®è¨­å®š

#### 2.8.1 ãƒ†ã‚¹ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼ˆ.github/workflows/test.ymlï¼‰

```yaml
name: Tests

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        python-version: ['3.10', '3.11']
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio
      
      - name: Run tests with coverage
        run: |
          pytest tests/ -v --cov=app --cov-report=xml --cov-report=html
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          fail_ci_if_error: false

  lint:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Install linting tools
        run: |
          pip install black flake8 mypy
      
      - name: Check formatting with Black
        run: black --check app/ tests/
      
      - name: Lint with flake8
        run: flake8 app/ tests/ --max-line-length=100
      
      - name: Type check with mypy
        run: mypy app/ --ignore-missing-imports
```

### Step 2-9: åˆæœŸã‚³ãƒŸãƒƒãƒˆã¨ãƒ—ãƒƒã‚·ãƒ¥

```bash
# ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°
git add .

# åˆæœŸã‚³ãƒŸãƒƒãƒˆ
git commit -m "feat: Initial project structure with core RAG implementation

- Add FastAPI backend with query and ingest endpoints
- Implement hybrid search (semantic + BM25) with RRF fusion
- Add Streamlit UI for interactive querying
- Configure Docker and docker-compose for deployment
- Set up GitHub Actions for CI/CD
- Add comprehensive documentation"

# ãƒªãƒ¢ãƒ¼ãƒˆã«ãƒ—ãƒƒã‚·ãƒ¥
git push origin main
```

### Step 2-10: ãƒªãƒã‚¸ãƒˆãƒªã‚’Pinned Repositoriesã«è¿½åŠ 

1. GitHubãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒšãƒ¼ã‚¸ï¼ˆ`https://github.com/jinno-ai`ï¼‰ã«ã‚¢ã‚¯ã‚»ã‚¹
2. ã€ŒCustomize your pinsã€ã‚’ã‚¯ãƒªãƒƒã‚¯
3. `enterprise-rag-system` ã«ãƒã‚§ãƒƒã‚¯ã‚’å…¥ã‚Œã‚‹
4. ã€ŒSave pinsã€ã‚’ã‚¯ãƒªãƒƒã‚¯

---

## âœ… Phase 3: LLM Agent Framework ãƒªãƒã‚¸ãƒˆãƒªã®ä½œæˆ

### ğŸ¯ ç›®æ¨™

ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯è‡ªå‹•åŒ–èƒ½åŠ›ã‚’ç¤ºã™ã€‚

### ğŸ“ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LLM Agent Framework                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                   Supervisor Agent                       â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚  â”‚  Task Analysis â†’ Agent Selection â†’ Coordination  â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                             â”‚                                   â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚         â”‚                   â”‚                   â”‚              â”‚
â”‚         â–¼                   â–¼                   â–¼              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Research   â”‚    â”‚    Code     â”‚    â”‚    Data     â”‚        â”‚
â”‚  â”‚   Agent     â”‚    â”‚   Agent     â”‚    â”‚   Agent     â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚         â”‚                  â”‚                  â”‚                â”‚
â”‚         â–¼                  â–¼                  â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Web Search  â”‚    â”‚   Python    â”‚    â”‚    SQL      â”‚        â”‚
â”‚  â”‚ Wikipedia   â”‚    â”‚  Executor   â”‚    â”‚   Pandas    â”‚        â”‚
â”‚  â”‚ Document    â”‚    â”‚   GitHub    â”‚    â”‚   Plotly    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚       Tools              Tools              Tools              â”‚
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    Shared Memory                         â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚
â”‚  â”‚  â”‚ Context â”‚  â”‚ Results â”‚  â”‚  State  â”‚  â”‚  Logs   â”‚    â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“Š ReActãƒ‘ã‚¿ãƒ¼ãƒ³è©³ç´°

```text
ReAct (Reasoning + Acting) Pattern:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚  User Query: "Research AI trends and create visualization"  â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ THOUGHT 1: I need to find information about AI      â”‚   â”‚
â”‚  â”‚            trends. I'll use web search.             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚                                   â”‚
â”‚                         â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ACTION 1: search("AI trends 2025")                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚                                   â”‚
â”‚                         â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ OBSERVATION 1: [Search results with 15 articles]    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚                                   â”‚
â”‚                         â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ THOUGHT 2: I found relevant articles. Now I need    â”‚   â”‚
â”‚  â”‚            to extract key statistics for viz.       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚                                   â”‚
â”‚                         â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ACTION 2: extract_data(articles)                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚                                   â”‚
â”‚                         â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ OBSERVATION 2: [Structured data with trends]        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚                                   â”‚
â”‚                         â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ THOUGHT 3: Data extracted. Now create Python        â”‚   â”‚
â”‚  â”‚            visualization script.                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚                                   â”‚
â”‚                         â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ACTION 3: python_execute(visualization_code)        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚                                   â”‚
â”‚                         â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ OBSERVATION 3: [Chart saved to ai_trends.png]       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚                                   â”‚
â”‚                         â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ FINAL ANSWER: Created visualization showing top     â”‚   â”‚
â”‚  â”‚ AI trends: RAG (35%), Agents (28%), Multi-modal...  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Step 3-1: ãƒªãƒã‚¸ãƒˆãƒªä½œæˆ

```bash
# GitHubä¸Šã§æ–°è¦ãƒªãƒã‚¸ãƒˆãƒªã‚’ä½œæˆ
# ãƒªãƒã‚¸ãƒˆãƒªå: llm-agent-framework
# èª¬æ˜: Multi-agent orchestration system for complex task automation
# Public ãƒªãƒã‚¸ãƒˆãƒª
# README, .gitignore (Python), MIT License ã‚’è¿½åŠ 
```

### Step 3-2: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®ä½œæˆ

```bash
# ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/jinno-ai/llm-agent-framework.git
cd llm-agent-framework

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ä½œæˆ
mkdir -p agent_framework/agents
mkdir -p agent_framework/tools
mkdir -p agent_framework/memory
mkdir -p agent_framework/utils
mkdir -p examples
mkdir -p tests/unit
mkdir -p tests/integration
mkdir -p docs

# __init__.py ã‚’ä½œæˆ
touch agent_framework/__init__.py
touch agent_framework/agents/__init__.py
touch agent_framework/tools/__init__.py
touch agent_framework/memory/__init__.py
touch agent_framework/utils/__init__.py
touch tests/__init__.py
```

### Step 3-3: ã‚³ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã®å®Ÿè£…

#### 3.3.1 ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆagent_framework/agents/base.pyï¼‰

```python
"""
Base Agent class for all specialized agents
"""

from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from enum import Enum
import logging

logger = logging.getLogger(__name__)


class AgentStatus(Enum):
    """Agent execution status"""
    IDLE = "idle"
    THINKING = "thinking"
    ACTING = "acting"
    COMPLETED = "completed"
    ERROR = "error"


@dataclass
class AgentAction:
    """Represents an action taken by an agent"""
    tool: str
    tool_input: Dict[str, Any]
    log: str


@dataclass
class AgentObservation:
    """Represents an observation from tool execution"""
    content: str
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class AgentStep:
    """A single step in the agent's reasoning"""
    thought: str
    action: Optional[AgentAction] = None
    observation: Optional[AgentObservation] = None


class BaseAgent(ABC):
    """
    Abstract base class for all agents.
    
    Implements the ReAct (Reasoning + Acting) pattern:
    1. THOUGHT: Reason about the current state
    2. ACTION: Choose and execute a tool
    3. OBSERVATION: Process the result
    4. Repeat until task is complete
    """
    
    def __init__(
        self,
        name: str,
        description: str,
        tools: List[str] = None,
        max_iterations: int = 10,
        verbose: bool = True,
    ):
        self.name = name
        self.description = description
        self.tools = tools or []
        self.max_iterations = max_iterations
        self.verbose = verbose
        self.status = AgentStatus.IDLE
        self.steps: List[AgentStep] = []
    
    @abstractmethod
    async def think(self, task: str, context: Dict[str, Any]) -> str:
        """
        Generate a thought about the current state.
        
        Args:
            task: The current task description
            context: Current context including previous steps
            
        Returns:
            The agent's thought process
        """
        pass
    
    @abstractmethod
    async def act(self, thought: str, context: Dict[str, Any]) -> AgentAction:
        """
        Decide on and prepare an action based on the thought.
        
        Args:
            thought: The current thought
            context: Current context
            
        Returns:
            The action to take
        """
        pass
    
    @abstractmethod
    async def observe(self, action: AgentAction) -> AgentObservation:
        """
        Execute the action and observe the result.
        
        Args:
            action: The action to execute
            
        Returns:
            The observation from executing the action
        """
        pass
    
    async def execute(self, task: str) -> str:
        """
        Execute the full ReAct loop for a task.
        
        Args:
            task: The task to complete
            
        Returns:
            The final answer or result
        """
        self.status = AgentStatus.THINKING
        self.steps = []
        context = {"task": task, "steps": []}
        
        for iteration in range(self.max_iterations):
            if self.verbose:
                logger.info(f"[{self.name}] Iteration {iteration + 1}")
            
            # THOUGHT
            thought = await self.think(task, context)
            if self.verbose:
                logger.info(f"[{self.name}] THOUGHT: {thought}")
            
            # Check if we have a final answer
            if self._is_final_answer(thought):
                self.status = AgentStatus.COMPLETED
                return self._extract_final_answer(thought)
            
            # ACTION
            self.status = AgentStatus.ACTING
            action = await self.act(thought, context)
            if self.verbose:
                logger.info(f"[{self.name}] ACTION: {action.tool}({action.tool_input})")
            
            # OBSERVATION
            observation = await self.observe(action)
            if self.verbose:
                logger.info(f"[{self.name}] OBSERVATION: {observation.content[:200]}...")
            
            # Record step
            step = AgentStep(thought=thought, action=action, observation=observation)
            self.steps.append(step)
            context["steps"].append(step)
            
            self.status = AgentStatus.THINKING
        
        # Max iterations reached
        self.status = AgentStatus.ERROR
        return "Max iterations reached without finding an answer."
    
    def _is_final_answer(self, thought: str) -> bool:
        """Check if the thought contains a final answer"""
        return "FINAL ANSWER:" in thought.upper()
    
    def _extract_final_answer(self, thought: str) -> str:
        """Extract the final answer from the thought"""
        if "FINAL ANSWER:" in thought.upper():
            idx = thought.upper().index("FINAL ANSWER:")
            return thought[idx + len("FINAL ANSWER:"):].strip()
        return thought
```

#### 3.3.2 ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆagent_framework/agents/research.pyï¼‰

```python
"""
Research Agent for web search and information gathering
"""

from typing import Dict, Any, List
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

from .base import BaseAgent, AgentAction, AgentObservation
from ..tools.search import WebSearchTool, WikipediaTool


class ResearchAgent(BaseAgent):
    """
    Specialized agent for research tasks.
    
    Capabilities:
    - Web search using multiple search engines
    - Wikipedia lookups
    - Document retrieval and summarization
    - Fact verification
    """
    
    def __init__(
        self,
        llm_model: str = "gpt-4",
        temperature: float = 0.0,
        **kwargs,
    ):
        super().__init__(
            name="ResearchAgent",
            description="Specialized in web search, information gathering, and fact verification",
            tools=["web_search", "wikipedia", "document_retrieval"],
            **kwargs,
        )
        
        self.llm = ChatOpenAI(model=llm_model, temperature=temperature)
        self.web_search = WebSearchTool()
        self.wikipedia = WikipediaTool()
        
        self.think_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a research agent. Your job is to find accurate information.

Available tools:
- web_search: Search the web for current information
- wikipedia: Look up factual information on Wikipedia
- document_retrieval: Search internal documents

Based on the task and previous steps, decide what to do next.
If you have enough information, respond with "FINAL ANSWER: [your answer]"

Previous steps:
{steps}
"""),
            ("human", "Task: {task}\n\nWhat should I do next?"),
        ])
        
        self.act_prompt = ChatPromptTemplate.from_messages([
            ("system", """Based on the thought, choose a tool and provide input.
Respond in JSON format:
{{"tool": "tool_name", "input": {{"query": "search query"}}}}
"""),
            ("human", "Thought: {thought}"),
        ])
    
    async def think(self, task: str, context: Dict[str, Any]) -> str:
        """Generate a thought about what to research next"""
        steps_str = self._format_steps(context.get("steps", []))
        
        response = await self.llm.ainvoke(
            self.think_prompt.format_messages(task=task, steps=steps_str)
        )
        return response.content
    
    async def act(self, thought: str, context: Dict[str, Any]) -> AgentAction:
        """Decide which research tool to use"""
        response = await self.llm.ainvoke(
            self.act_prompt.format_messages(thought=thought)
        )
        
        # Parse the JSON response
        import json
        action_data = json.loads(response.content)
        
        return AgentAction(
            tool=action_data["tool"],
            tool_input=action_data["input"],
            log=f"Using {action_data['tool']} to research",
        )
    
    async def observe(self, action: AgentAction) -> AgentObservation:
        """Execute the research tool and return results"""
        if action.tool == "web_search":
            results = await self.web_search.search(action.tool_input["query"])
            return AgentObservation(
                content=self._format_search_results(results),
                metadata={"source": "web_search", "num_results": len(results)},
            )
        elif action.tool == "wikipedia":
            content = await self.wikipedia.lookup(action.tool_input["query"])
            return AgentObservation(
                content=content,
                metadata={"source": "wikipedia"},
            )
        else:
            return AgentObservation(
                content=f"Unknown tool: {action.tool}",
                metadata={"error": True},
            )
    
    def _format_steps(self, steps: List) -> str:
        """Format previous steps for the prompt"""
        if not steps:
            return "No previous steps."
        
        formatted = []
        for i, step in enumerate(steps, 1):
            formatted.append(f"Step {i}:")
            formatted.append(f"  Thought: {step.thought}")
            if step.action:
                formatted.append(f"  Action: {step.action.tool}({step.action.tool_input})")
            if step.observation:
                formatted.append(f"  Observation: {step.observation.content[:200]}...")
        
        return "\n".join(formatted)
    
    def _format_search_results(self, results: List[Dict]) -> str:
        """Format search results for observation"""
        formatted = []
        for i, result in enumerate(results[:5], 1):
            formatted.append(f"{i}. {result['title']}")
            formatted.append(f"   URL: {result['url']}")
            formatted.append(f"   Snippet: {result['snippet']}")
        return "\n".join(formatted)
```

#### 3.3.3 ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒã‚¤ã‚¶ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆagent_framework/agents/supervisor.pyï¼‰

```python
"""
Supervisor Agent for orchestrating multiple specialized agents
"""

from typing import Dict, Any, List, Optional
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langgraph.graph import StateGraph, END

from .base import BaseAgent


class SupervisorAgent:
    """
    Orchestrates multiple specialized agents to complete complex tasks.
    
    Responsibilities:
    - Task analysis and decomposition
    - Agent selection and delegation
    - Result synthesis and coordination
    - Error handling and recovery
    """
    
    def __init__(
        self,
        llm_model: str = "gpt-4",
        temperature: float = 0.0,
    ):
        self.llm = ChatOpenAI(model=llm_model, temperature=temperature)
        self.agents: Dict[str, BaseAgent] = {}
        self.workflow = None
        
        self.routing_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a supervisor coordinating specialized agents.

Available agents:
{agent_descriptions}

Analyze the task and decide which agent should handle it.
If the task is complete, respond with "FINISH".
Otherwise, respond with the agent name.
"""),
            ("human", "Task: {task}\n\nCurrent progress:\n{progress}\n\nWhich agent should work next?"),
        ])
    
    def register_agent(self, agent: BaseAgent) -> None:
        """Register a specialized agent"""
        self.agents[agent.name] = agent
    
    def _build_workflow(self) -> StateGraph:
        """Build the LangGraph workflow"""
        workflow = StateGraph(dict)
        
        # Add supervisor node
        workflow.add_node("supervisor", self._supervisor_node)
        
        # Add agent nodes
        for name, agent in self.agents.items():
            workflow.add_node(name, self._create_agent_node(agent))
        
        # Add conditional edges from supervisor
        workflow.add_conditional_edges(
            "supervisor",
            self._route_to_agent,
            {name: name for name in self.agents.keys()} | {"FINISH": END},
        )
        
        # Add edges from agents back to supervisor
        for name in self.agents.keys():
            workflow.add_edge(name, "supervisor")
        
        workflow.set_entry_point("supervisor")
        
        return workflow.compile()
    
    async def _supervisor_node(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """Supervisor decision node"""
        agent_descriptions = "\n".join([
            f"- {name}: {agent.description}"
            for name, agent in self.agents.items()
        ])
        
        progress = state.get("progress", "No progress yet.")
        
        response = await self.llm.ainvoke(
            self.routing_prompt.format_messages(
                agent_descriptions=agent_descriptions,
                task=state["task"],
                progress=progress,
            )
        )
        
        state["next_agent"] = response.content.strip()
        return state
    
    def _route_to_agent(self, state: Dict[str, Any]) -> str:
        """Route to the next agent or finish"""
        next_agent = state.get("next_agent", "FINISH")
        if next_agent in self.agents:
            return next_agent
        return "FINISH"
    
    def _create_agent_node(self, agent: BaseAgent):
        """Create a node function for an agent"""
        async def agent_node(state: Dict[str, Any]) -> Dict[str, Any]:
            result = await agent.execute(state["task"])
            state["progress"] = state.get("progress", "") + f"\n{agent.name}: {result}"
            state["results"] = state.get("results", []) + [{"agent": agent.name, "result": result}]
            return state
        return agent_node
    
    async def execute(self, task: str) -> Dict[str, Any]:
        """
        Execute a complex task using multiple agents.
        
        Args:
            task: The task description
            
        Returns:
            Dictionary with results from all agents
        """
        if self.workflow is None:
            self.workflow = self._build_workflow()
        
        initial_state = {
            "task": task,
            "progress": "",
            "results": [],
        }
        
        final_state = await self.workflow.ainvoke(initial_state)
        
        return {
            "task": task,
            "results": final_state.get("results", []),
            "final_progress": final_state.get("progress", ""),
        }
```

### Step 3-4: ä½¿ç”¨ä¾‹ï¼ˆexamples/basic_usage.pyï¼‰

```python
"""
Basic usage example for LLM Agent Framework
"""

import asyncio
from agent_framework import SupervisorAgent, ResearchAgent, CodeAgent


async def main():
    # Initialize supervisor
    supervisor = SupervisorAgent(llm_model="gpt-4")
    
    # Create and register specialized agents
    research_agent = ResearchAgent()
    code_agent = CodeAgent()
    
    supervisor.register_agent(research_agent)
    supervisor.register_agent(code_agent)
    
    # Execute a complex task
    result = await supervisor.execute(
        "Research the latest trends in AI and create a Python script to visualize them"
    )
    
    print("=" * 50)
    print("Task Completed!")
    print("=" * 50)
    
    for agent_result in result["results"]:
        print(f"\n{agent_result['agent']}:")
        print(f"  {agent_result['result'][:200]}...")
    
    print(f"\nFinal Progress:\n{result['final_progress']}")


if __name__ == "__main__":
    asyncio.run(main())
```

### Step 3-5: åˆæœŸã‚³ãƒŸãƒƒãƒˆã¨ãƒ—ãƒƒã‚·ãƒ¥

```bash
# READMEã‚’é…ç½®
cp /path/to/jinno-ai-portfolio-kit/llm-agent-framework-README.md README.md

# ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°
git add .

# ã‚³ãƒŸãƒƒãƒˆ
git commit -m "feat: Initial multi-agent framework with LangGraph

- Implement BaseAgent with ReAct pattern
- Add ResearchAgent for web search and information gathering
- Add SupervisorAgent for multi-agent orchestration
- Configure LangGraph workflow for agent coordination
- Add usage examples and documentation"

# ãƒ—ãƒƒã‚·ãƒ¥
git push origin main
```

---

## âœ… Phase 4: è¿½åŠ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä½œæˆ

### 4-1: realtime-edge-detection

#### ğŸ“ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Real-time Edge Detection System                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   Camera    â”‚â”€â”€â”€â–¶â”‚   Frame     â”‚â”€â”€â”€â–¶â”‚   YOLO v8   â”‚    â”‚
â”‚  â”‚   Input     â”‚    â”‚  Capture    â”‚    â”‚   Model     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                               â”‚            â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                     â”‚                                      â”‚
â”‚                     â–¼                                      â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚              â”‚  TensorRT   â”‚  â† GPU Optimization           â”‚
â”‚              â”‚  Engine     â”‚                               â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                     â”‚                                      â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚         â”‚           â”‚           â”‚                         â”‚
â”‚         â–¼           â–¼           â–¼                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  Bounding   â”‚ â”‚   Class     â”‚ â”‚ Confidence  â”‚         â”‚
â”‚  â”‚   Boxes     â”‚ â”‚   Labels    â”‚ â”‚   Scores    â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚         â”‚               â”‚               â”‚                 â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                         â”‚                                 â”‚
â”‚                         â–¼                                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚              â”‚   Visualization â”‚                          â”‚
â”‚              â”‚   & Output      â”‚                          â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                                           â”‚
â”‚  Performance: 30+ FPS on Raspberry Pi 4 / Jetson Nano    â”‚
â”‚                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

```bash
# ãƒªãƒã‚¸ãƒˆãƒªä½œæˆ
# GitHubä¸Šã§: realtime-edge-detection
# èª¬æ˜: Low-latency object detection optimized for edge devices

# ã‚¯ãƒ­ãƒ¼ãƒ³ã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
git clone https://github.com/jinno-ai/realtime-edge-detection.git
cd realtime-edge-detection

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
mkdir -p src/models src/utils src/inference
mkdir -p configs examples tests docs/images
mkdir -p deployment/raspberry_pi deployment/jetson

# ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
touch src/__init__.py
touch src/models/__init__.py
touch src/detector.py
touch src/optimizer.py
touch configs/yolov8_config.yaml
```

#### æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

| ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ | æŠ€è¡“ | å½¹å‰² |
|---------------|------|------|
| ãƒ¢ãƒ‡ãƒ« | YOLO v8 | ç‰©ä½“æ¤œå‡º |
| æœ€é©åŒ– | TensorRT | GPUæ¨è«–é«˜é€ŸåŒ– |
| ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ | OpenCV | ç”»åƒå‡¦ç† |
| ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ | ONNX | ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ  |
| ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹ | Raspberry Pi, Jetson | ãƒ‡ãƒ—ãƒ­ã‚¤å…ˆ |

### 4-2: multilingual-sentiment-analyzer

#### ğŸ“ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Multilingual Sentiment Analyzer                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚  â”‚   Input     â”‚  Japanese / English / Chinese             â”‚
â”‚  â”‚   Text      â”‚                                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚         â”‚                                                   â”‚
â”‚         â–¼                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Language Detection                      â”‚   â”‚
â”‚  â”‚              (fastText / langdetect)                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚                                   â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚         â”‚               â”‚               â”‚                  â”‚
â”‚         â–¼               â–¼               â–¼                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  Japanese   â”‚ â”‚   English   â”‚ â”‚   Chinese   â”‚          â”‚
â”‚  â”‚  Tokenizer  â”‚ â”‚  Tokenizer  â”‚ â”‚  Tokenizer  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚               â”‚               â”‚                  â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                         â”‚                                   â”‚
â”‚                         â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              XLM-RoBERTa Model                       â”‚   â”‚
â”‚  â”‚         (Fine-tuned for Sentiment)                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚                                   â”‚
â”‚                         â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Output: Positive / Negative / Neutral + Score     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

```bash
# ãƒªãƒã‚¸ãƒˆãƒªä½œæˆ
# GitHubä¸Šã§: multilingual-sentiment-analyzer
# èª¬æ˜: Cross-lingual sentiment analysis with fine-tuned transformers

# ã‚¯ãƒ­ãƒ¼ãƒ³ã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
git clone https://github.com/jinno-ai/multilingual-sentiment-analyzer.git
cd multilingual-sentiment-analyzer

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
mkdir -p src/models src/preprocessing src/api
mkdir -p data/train data/test data/raw
mkdir -p notebooks configs tests
mkdir -p deployment/docker

# ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
touch src/__init__.py
touch src/analyzer.py
touch src/api/main.py
touch configs/model_config.yaml
```

### 4-3: micro-instruction-engineering

#### ğŸ“ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ¦‚è¦

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Micro-Instruction Engineering Framework           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Traditional Prompt:                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ "Summarize this article and extract key points"     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚                                   â”‚
â”‚                         â–¼                                   â”‚
â”‚  Micro-Instruction Decomposition:                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Step 1: Read and understand the article             â”‚   â”‚
â”‚  â”‚ Step 2: Identify the main topic                     â”‚   â”‚
â”‚  â”‚ Step 3: Extract 3-5 key points                      â”‚   â”‚
â”‚  â”‚ Step 4: Summarize in 2-3 sentences                  â”‚   â”‚
â”‚  â”‚ Step 5: Format output as bullet points              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚  Benefits:                                                  â”‚
â”‚  âœ… +40% accuracy improvement                              â”‚
â”‚  âœ… More consistent outputs                                â”‚
â”‚  âœ… Better reasoning chains                                â”‚
â”‚  âœ… Easier debugging                                       â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

```bash
# ãƒªãƒã‚¸ãƒˆãƒªä½œæˆ
# GitHubä¸Šã§: micro-instruction-engineering
# èª¬æ˜: Systematic methodology for prompt optimization & AI reasoning

# ã‚¯ãƒ­ãƒ¼ãƒ³ã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
git clone https://github.com/jinno-ai/micro-instruction-engineering.git
cd micro-instruction-engineering

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
mkdir -p src/decomposer src/evaluator src/optimizer
mkdir -p notebooks examples benchmarks
mkdir -p data/prompts data/results
mkdir -p docs/methodology

# ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
touch src/__init__.py
touch src/decomposer/instruction_decomposer.py
touch src/evaluator/prompt_evaluator.py
touch notebooks/01_introduction.ipynb
touch notebooks/02_decomposition_examples.ipynb
```

---

## âœ… Phase 5: READMEå“è³ªå‘ä¸Š

### 5-1: ãƒ‡ãƒ¢GIF/å‹•ç”»ã®ä½œæˆ

#### æ¨å¥¨ãƒ„ãƒ¼ãƒ«

| OS | ãƒ„ãƒ¼ãƒ« | ç‰¹å¾´ |
|----|--------|------|
| Windows | ScreenToGif | è»½é‡ã€ç·¨é›†æ©Ÿèƒ½ä»˜ã |
| Mac | Kap | ã‚·ãƒ³ãƒ—ãƒ«ã€é«˜å“è³ª |
| Linux | Peek | GTKå¯¾å¿œã€è»½é‡ |
| ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ  | OBS Studio | é«˜æ©Ÿèƒ½ã€å‹•ç”»ã‚‚å¯ |

#### GIFä½œæˆæ‰‹é †ï¼ˆScreenToGifã®ä¾‹ï¼‰

```text
1. ScreenToGifã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
   https://www.screentogif.com/

2. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•

3. ã€ŒRecorderã€ã‚’é¸æŠ

4. éŒ²ç”»ç¯„å›²ã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã«åˆã‚ã›ã‚‹

5. ã€ŒRecordã€ãƒœã‚¿ãƒ³ã§éŒ²ç”»é–‹å§‹

6. ãƒ‡ãƒ¢æ“ä½œã‚’å®Ÿè¡Œ:
   - ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›
   - æ¤œç´¢ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
   - çµæœãŒè¡¨ç¤ºã•ã‚Œã‚‹ã¾ã§å¾…æ©Ÿ

7. ã€ŒStopã€ã§éŒ²ç”»çµ‚äº†

8. ã‚¨ãƒ‡ã‚£ã‚¿ã§ç·¨é›†:
   - ä¸è¦ãªãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‰Šé™¤
   - ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆã‚’èª¿æ•´ï¼ˆ15-20fpsæ¨å¥¨ï¼‰
   - ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’æœ€é©åŒ–ï¼ˆ5MBä»¥ä¸‹æ¨å¥¨ï¼‰

9. ã€ŒSave Asã€ã§GIFã¨ã—ã¦ä¿å­˜
   ä¿å­˜å…ˆ: docs/images/demo.gif
```

#### GIFæœ€é©åŒ–ã®ã‚³ãƒ„

```text
âœ… æ¨å¥¨è¨­å®š:
- è§£åƒåº¦: 800x600 ä»¥ä¸‹
- ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆ: 15-20 fps
- é•·ã•: 10-30ç§’
- ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 5MBä»¥ä¸‹

âŒ é¿ã‘ã‚‹ã¹ã:
- 4Kè§£åƒåº¦ã§ã®éŒ²ç”»
- 60fpsã§ã®éŒ²ç”»
- 1åˆ†ä»¥ä¸Šã®é•·ã„GIF
- 10MBä»¥ä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«
```

### 5-2: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³ã®ä½œæˆ

#### Mermaidã‚’ä½¿ç”¨ã—ãŸå›³ï¼ˆREADMEå†…ã«ç›´æ¥è¨˜è¿°ï¼‰

```markdown
## Architecture

```mermaid
graph TB
    A[User Query] --> B[API Gateway]
    B --> C[Query Processor]
    C --> D{Search Type}
    D -->|Semantic| E[Vector DB]
    D -->|Keyword| F[BM25 Index]
    E --> G[Result Fusion]
    F --> G
    G --> H[Re-Ranker]
    H --> I[LLM Generator]
    I --> J[Response]
```
```

#### draw.ioã‚’ä½¿ç”¨ã—ãŸå›³

```text
1. draw.io (https://app.diagrams.net/) ã«ã‚¢ã‚¯ã‚»ã‚¹

2. ã€ŒCreate New Diagramã€ã‚’é¸æŠ

3. ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰ã€ŒFlowchartã€ã‚’é¸æŠ

4. ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’é…ç½®:
   - Rectangle: ã‚µãƒ¼ãƒ“ã‚¹/ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
   - Diamond: åˆ¤æ–­ãƒã‚¤ãƒ³ãƒˆ
   - Cylinder: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
   - Arrow: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼

5. ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š:
   - ãƒ•ã‚©ãƒ³ãƒˆ: Arial ã¾ãŸã¯ Roboto
   - è‰²: ä¸€è²«ã—ãŸã‚«ãƒ©ãƒ¼ã‚¹ã‚­ãƒ¼ãƒ 
   - ç·š: 2pxã€çŸ¢å°ä»˜ã

6. ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ:
   - Format: PNG (é€éèƒŒæ™¯)
   - Scale: 2x (é«˜è§£åƒåº¦)
   - ä¿å­˜å…ˆ: docs/images/architecture.png
```

### 5-3: ãƒãƒƒã‚¸ã®è¿½åŠ 

#### åŸºæœ¬ãƒãƒƒã‚¸ã‚»ãƒƒãƒˆ

```markdown
<!-- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®çŠ¶æ…‹ -->
![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Status](https://img.shields.io/badge/status-active-success.svg)
![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)

<!-- GitHubçµ±è¨ˆ -->
![Stars](https://img.shields.io/github/stars/jinno-ai/enterprise-rag-system)
![Forks](https://img.shields.io/github/forks/jinno-ai/enterprise-rag-system)
![Issues](https://img.shields.io/github/issues/jinno-ai/enterprise-rag-system)
![Last Commit](https://img.shields.io/github/last-commit/jinno-ai/enterprise-rag-system)

<!-- CI/CD -->
![Tests](https://github.com/jinno-ai/enterprise-rag-system/workflows/Tests/badge.svg)
![Coverage](https://codecov.io/gh/jinno-ai/enterprise-rag-system/branch/main/graph/badge.svg)

<!-- æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ -->
![FastAPI](https://img.shields.io/badge/FastAPI-009688?logo=fastapi&logoColor=white)
![LangChain](https://img.shields.io/badge/LangChain-1C3C3C?logo=chainlink&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?logo=docker&logoColor=white)
```

#### ã‚«ã‚¹ã‚¿ãƒ ãƒãƒƒã‚¸ã®ä½œæˆ

```text
shields.io ã§ã‚«ã‚¹ã‚¿ãƒ ãƒãƒƒã‚¸ã‚’ä½œæˆ:

URLå½¢å¼:
https://img.shields.io/badge/{LABEL}-{MESSAGE}-{COLOR}

ä¾‹:
- https://img.shields.io/badge/accuracy-85%25-brightgreen
- https://img.shields.io/badge/latency-<3s-blue
- https://img.shields.io/badge/docs-comprehensive-orange
```

---

## âœ… Phase 6: GitHub Actionsã®è¨­å®š

### 6-1: è‡ªå‹•ãƒ†ã‚¹ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

`.github/workflows/test.yml`:

```yaml
name: Tests

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  PYTHON_VERSION: '3.10'

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio
      
      - name: Run unit tests
        run: pytest tests/unit -v --cov=app --cov-report=xml
      
      - name: Run integration tests
        run: pytest tests/integration -v
        env:
          REDIS_HOST: localhost
          REDIS_PORT: 6379
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml

  lint:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install linters
        run: pip install black flake8 isort mypy
      
      - name: Check formatting
        run: |
          black --check app/ tests/
          isort --check-only app/ tests/
      
      - name: Lint code
        run: flake8 app/ tests/ --max-line-length=100
      
      - name: Type check
        run: mypy app/ --ignore-missing-imports

  security:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Run security scan
        uses: pyupio/safety@v2.3.5
        with:
          api-key: ${{ secrets.SAFETY_API_KEY }}
```

### 6-2: è‡ªå‹•ãƒªãƒªãƒ¼ã‚¹ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

`.github/workflows/release.yml`:

```yaml
name: Release

on:
  push:
    tags:
      - 'v*'

jobs:
  release:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Build package
        run: |
          pip install build
          python -m build
      
      - name: Create Release
        uses: softprops/action-gh-release@v1
        with:
          files: dist/*
          generate_release_notes: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: |
            ghcr.io/${{ github.repository }}:${{ github.ref_name }}
            ghcr.io/${{ github.repository }}:latest
```

---

## âœ… Phase 7: ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å¼·åŒ–

### 7-1: GitHub Statsè¨­å®š

Profile READMEã«è¿½åŠ ã™ã‚‹Stats:

```markdown
## ğŸ“Š GitHub Stats

<div align="center">

<!-- åŸºæœ¬çµ±è¨ˆ -->
![GitHub stats](https://github-readme-stats.vercel.app/api?username=jinno-ai&show_icons=true&theme=tokyonight&hide_border=true&bg_color=0D1117&title_color=00D9FF&icon_color=00D9FF&text_color=C9D1D9)

<!-- ä½¿ç”¨è¨€èª -->
![Top Langs](https://github-readme-stats.vercel.app/api/top-langs/?username=jinno-ai&layout=compact&theme=tokyonight&hide_border=true&bg_color=0D1117&title_color=00D9FF&text_color=C9D1D9)

<!-- ã‚³ãƒŸãƒƒãƒˆã‚¹ãƒˆãƒªãƒ¼ã‚¯ -->
![GitHub Streak](https://github-readme-streak-stats.herokuapp.com/?user=jinno-ai&theme=tokyonight&hide_border=true&background=0D1117&stroke=00D9FF&ring=00D9FF&fire=FF6B6B&currStreakLabel=00D9FF)

<!-- ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã‚°ãƒ©ãƒ• -->
![Activity Graph](https://github-readme-activity-graph.vercel.app/graph?username=jinno-ai&theme=tokyo-night&hide_border=true&bg_color=0D1117)

</div>
```

### 7-2: Skill Iconsã®è¨­å®š

```markdown
## ğŸ› ï¸ Tech Stack

<!-- skillicons.dev ã‚’ä½¿ç”¨ -->
![My Skills](https://skillicons.dev/icons?i=python,pytorch,tensorflow,docker,kubernetes,aws,gcp,fastapi,react,typescript&perline=5)

<!-- ã¾ãŸã¯å€‹åˆ¥ãƒãƒƒã‚¸ -->
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)
```

---

## âœ… Phase 8: ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ´»å‹•

### 8-1: Issues & Discussionsæœ‰åŠ¹åŒ–

å„ãƒªãƒã‚¸ãƒˆãƒªã§ä»¥ä¸‹ã‚’è¨­å®š:

```text
1. ãƒªãƒã‚¸ãƒˆãƒªãƒšãƒ¼ã‚¸ã§ã€ŒSettingsã€ã‚¿ãƒ–ã‚’ã‚¯ãƒªãƒƒã‚¯

2. å·¦ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ã€ŒGeneralã€ã‚’é¸æŠ

3. ã€ŒFeaturesã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¾ã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«

4. ä»¥ä¸‹ã«ãƒã‚§ãƒƒã‚¯ã‚’å…¥ã‚Œã‚‹:
   âœ… Issues
   âœ… Discussions (ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ§‹ç¯‰ç”¨)
   âœ… Projects (ã‚¿ã‚¹ã‚¯ç®¡ç†ç”¨)
   âœ… Wiki (ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”¨ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³)

5. ã€ŒSaveã€ã‚’ã‚¯ãƒªãƒƒã‚¯
```

### 8-2: Issue/PRãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ä½œæˆ

`.github/ISSUE_TEMPLATE/bug_report.md`:

```markdown
---
name: Bug Report
about: Report a bug to help us improve
title: '[BUG] '
labels: bug
assignees: ''
---

## Bug Description
A clear and concise description of the bug.

## Steps to Reproduce
1. Go to '...'
2. Click on '...'
3. See error

## Expected Behavior
What you expected to happen.

## Actual Behavior
What actually happened.

## Environment
- OS: [e.g., Ubuntu 22.04]
- Python version: [e.g., 3.10]
- Package version: [e.g., 1.0.0]

## Additional Context
Any other context about the problem.
```

`.github/PULL_REQUEST_TEMPLATE.md`:

```markdown
## Description
Brief description of the changes.

## Type of Change
- [ ] Bug fix
- [ ] New feature
- [ ] Breaking change
- [ ] Documentation update

## Checklist
- [ ] My code follows the project's style guidelines
- [ ] I have performed a self-review
- [ ] I have added tests that prove my fix/feature works
- [ ] New and existing tests pass locally
- [ ] I have updated the documentation accordingly

## Related Issues
Fixes #(issue number)
```

### 8-3: CONTRIBUTINGã‚¬ã‚¤ãƒ‰

`CONTRIBUTING.md`:

```markdown
# Contributing to Enterprise RAG System

Thank you for your interest in contributing! This document provides guidelines and instructions for contributing.

## ğŸš€ Getting Started

### Prerequisites
- Python 3.10+
- Docker & Docker Compose
- Git

### Development Setup

```bash
# Clone the repository
git clone https://github.com/jinno-ai/enterprise-rag-system.git
cd enterprise-rag-system

# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
pip install -r requirements-dev.txt

# Install pre-commit hooks
pre-commit install
```

## ğŸ“ Code Style

We follow these conventions:
- **PEP 8** for Python code style
- **Black** for code formatting
- **isort** for import sorting
- **Type hints** for all functions

Run formatters before committing:
```bash
black app/ tests/
isort app/ tests/
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/

# Run with coverage
pytest tests/ --cov=app --cov-report=html

# Run specific test file
pytest tests/unit/test_retriever.py -v
```

## ğŸ“¤ Submitting Changes

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Run tests and linters
5. Commit with a descriptive message
6. Push to your fork
7. Open a Pull Request

### Commit Message Format

```text
type(scope): subject

body (optional)

footer (optional)
```

Types: `feat`, `fix`, `docs`, `style`, `refactor`, `test`, `chore`

Example:
```text
feat(retriever): add hybrid search with RRF fusion

- Implement semantic search using Pinecone
- Add BM25 keyword search
- Merge results using Reciprocal Rank Fusion

Closes #123
```

## ğŸ¤ Code of Conduct

Please be respectful and constructive in all interactions.

## ğŸ“ Questions?

- Open an issue for bugs or feature requests
- Start a discussion for questions
- Reach out on [Twitter](https://twitter.com/jinno_ai)
```

---

## âœ… Phase 9: ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³

### 9-1: Twitter/XæŠ•ç¨¿ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

#### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒªãƒªãƒ¼ã‚¹æŠ•ç¨¿

```text
ğŸš€ Just launched my Enterprise RAG System on GitHub!

A production-ready RAG pipeline with:
âœ… Hybrid search (semantic + keyword)
âœ… Multi-format document support
âœ… <3s response latency
âœ… 85%+ answer relevancy
âœ… Full observability with LangSmith

Built with #LangChain #Pinecone #GPT4

Check it out: https://github.com/jinno-ai/enterprise-rag-system

#AI #MachineLearning #RAG #OpenSource #Python
```

#### æŠ€è¡“è§£èª¬ã‚¹ãƒ¬ãƒƒãƒ‰

```text
ğŸ§µ Thread: How I built a production-grade RAG system

1/7 The problem: Enterprise knowledge is scattered across PDFs, Confluence, Notion...

Traditional search fails to capture semantic meaning.

Here's how I solved it ğŸ‘‡

---

2/7 Architecture Overview:

The system uses a hybrid search approach:
- Semantic search (dense vectors)
- Keyword search (BM25)
- Reciprocal Rank Fusion for merging

This gives the best of both worlds ğŸ¯

---

3/7 Key Components:

ğŸ“„ Document Ingestion: Unstructured.io
ğŸ”¢ Embeddings: OpenAI Ada-002
ğŸ—„ï¸ Vector DB: Pinecone
ğŸ” Search: Hybrid (semantic + BM25)
ğŸ¤– LLM: GPT-4 / Claude

---

4/7 Performance Results:

After testing on 10,000 enterprise docs:
- Answer Relevancy: 85.3%
- Faithfulness: 91.2%
- Latency (p95): 2.9s
- Cost per query: $0.03

---

5/7 The secret sauce: Re-ranking

Using Cross-Encoder models to re-rank results improved accuracy by 15%!

The model understands context better than simple similarity scores.

---

6/7 Lessons learned:

1. Chunking strategy matters A LOT
2. Hybrid search > pure semantic
3. Caching is essential for production
4. Monitor everything with LangSmith

---

7/7 Want to try it?

ğŸ”— GitHub: [link]
ğŸ“– Docs: [link]
ğŸ³ Docker: docker-compose up -d

Star â­ if you find it useful!

Questions? Reply below ğŸ‘‡
```

### 9-2: LinkedInæŠ•ç¨¿ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

```text
ğŸ¯ Excited to share my latest open-source project: Enterprise RAG System

After months of development and testing, I'm releasing a production-grade Retrieval-Augmented Generation pipeline designed for enterprise knowledge bases.

ğŸ”¥ Key Features:
â€¢ Hybrid search combining semantic and keyword approaches
â€¢ Multi-format document support (PDF, Markdown, Confluence, Notion)
â€¢ Sub-3-second response latency
â€¢ 85%+ answer relevancy on enterprise datasets
â€¢ Full observability with LangSmith integration

ğŸ’¡ Why I built this:
Modern enterprises struggle with information scattered across multiple systems. Traditional search fails to capture semantic meaning, and generic LLMs hallucinate without proper context.

This system bridges that gap with a production-ready architecture.

ğŸ› ï¸ Tech Stack:
â€¢ LangChain for orchestration
â€¢ Pinecone for vector storage
â€¢ GPT-4/Claude for generation
â€¢ FastAPI + Streamlit for API/UI
â€¢ Docker for deployment

ğŸ“Š Results:
Tested on 10,000 enterprise documents:
â€¢ Answer Relevancy: 85.3%
â€¢ Faithfulness: 91.2%
â€¢ Latency (p95): 2.9s

ğŸ”— Check it out: https://github.com/jinno-ai/enterprise-rag-system

I'd love to hear your feedback and suggestions!

#AI #MachineLearning #RAG #LLM #OpenSource #Python #LangChain
```

### 9-3: RedditæŠ•ç¨¿ã‚¬ã‚¤ãƒ‰

#### é©åˆ‡ãªã‚µãƒ–ãƒ¬ãƒ‡ã‚£ãƒƒãƒˆ

| ã‚µãƒ–ãƒ¬ãƒ‡ã‚£ãƒƒãƒˆ | å†…å®¹ | æŠ•ç¨¿ã‚¿ã‚¤ãƒ— |
|---------------|------|-----------|
| r/MachineLearning | ç ”ç©¶ãƒ»æŠ€è¡“ | [P] Project |
| r/learnmachinelearning | å­¦ç¿’è€…å‘ã‘ | ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ« |
| r/LocalLLaMA | ãƒ­ãƒ¼ã‚«ãƒ«LLM | å®Ÿè£…å…±æœ‰ |
| r/LangChain | LangChainé–¢é€£ | ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ |
| r/OpenSource | OSSå…¨èˆ¬ | ãƒªãƒªãƒ¼ã‚¹å‘ŠçŸ¥ |

#### æŠ•ç¨¿ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆr/MachineLearningï¼‰

```text
[P] Enterprise RAG System - Production-grade RAG pipeline with hybrid search

I've been working on a RAG system designed for enterprise use cases and wanted to share it with the community.

**Problem:**
Enterprise knowledge is scattered across multiple document formats and systems. Traditional keyword search fails to capture semantic meaning, and generic LLMs hallucinate without proper context.

**Solution:**
A hybrid search approach combining:
- Semantic search using dense vectors (Pinecone)
- Keyword search using BM25
- Reciprocal Rank Fusion for result merging
- Cross-Encoder re-ranking for improved accuracy

**Results:**
Tested on 10,000 enterprise documents:
- Answer Relevancy: 85.3% (RAGAS score)
- Faithfulness: 91.2%
- Latency (p95): 2.9s
- Cost per query: $0.03 (GPT-4 Turbo)

**Tech Stack:**
- LangChain for orchestration
- Pinecone for vector storage
- OpenAI Ada-002 for embeddings
- GPT-4/Claude for generation
- FastAPI + Streamlit

**GitHub:** [link]

Would love to hear feedback, especially on:
1. Chunking strategies for different document types
2. Evaluation methodologies
3. Production deployment experiences

Happy to answer any questions!
```

---

## ğŸ“Š æˆåŠŸæŒ‡æ¨™ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°

### é€±æ¬¡ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

```text
â–¡ æœ€ä½5ã‚³ãƒŸãƒƒãƒˆ (ç·‘ã®ãƒã‚¹ã‚’ç¶­æŒ)
  - æœˆæ›œ: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°
  - æ°´æ›œ: æ©Ÿèƒ½è¿½åŠ /ãƒã‚°ä¿®æ­£
  - é‡‘æ›œ: ãƒ†ã‚¹ãƒˆè¿½åŠ 
  - åœŸæ—¥: ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°/æ”¹å–„

â–¡ READMEæ›´æ–° (é€²æ—ã‚’åæ˜ )
  - æ–°æ©Ÿèƒ½ã®è¿½åŠ 
  - ãƒãƒƒã‚¸ã®æ›´æ–°
  - ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã®æ›´æ–°

â–¡ Issueså¯¾å¿œ (ã‚ã‚‹å ´åˆ)
  - 24æ™‚é–“ä»¥å†…ã«åˆå›è¿”ä¿¡
  - 1é€±é–“ä»¥å†…ã«ã‚¯ãƒ­ãƒ¼ã‚ºç›®æ¨™

â–¡ æŠ€è¡“ãƒ–ãƒ­ã‚°åŸ·ç­† (éš”é€±)
  - Medium ã¾ãŸã¯ Qiita
  - 1500-3000æ–‡å­—
  - ã‚³ãƒ¼ãƒ‰ä¾‹ã‚’å«ã‚ã‚‹

â–¡ SNSæŠ•ç¨¿ (é€±1å›)
  - é€²æ—å ±å‘Š
  - æŠ€è¡“Tips
  - ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£äº¤æµ
```

### æœˆæ¬¡ç›®æ¨™

```text
Month 1:
â”œâ”€â”€ Profile READMEå®Œæˆ âœ…
â”œâ”€â”€ enterprise-rag-system åˆç‰ˆãƒªãƒªãƒ¼ã‚¹
â”œâ”€â”€ llm-agent-framework åˆç‰ˆãƒªãƒªãƒ¼ã‚¹
â”œâ”€â”€ Stars: 10+ (åˆè¨ˆ)
â””â”€â”€ ãƒ–ãƒ­ã‚°è¨˜äº‹: 2æœ¬

Month 2:
â”œâ”€â”€ è¿½åŠ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ2ã¤å®Œæˆ
â”œâ”€â”€ ãƒ‡ãƒ¢GIF/å‹•ç”»è¿½åŠ 
â”œâ”€â”€ GitHub Actionsè¨­å®š
â”œâ”€â”€ Stars: 50+ (åˆè¨ˆ)
â””â”€â”€ ãƒ–ãƒ­ã‚°è¨˜äº‹: 4æœ¬ (ç´¯è¨ˆ)

Month 3:
â”œâ”€â”€ å…¨6ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œæˆ
â”œâ”€â”€ OSSè²¢çŒ®é–‹å§‹ (LangChainç­‰)
â”œâ”€â”€ Followers: 50+
â”œâ”€â”€ Stars: 100+ (åˆè¨ˆ)
â””â”€â”€ ä¼æ¥­ã‹ã‚‰ã®ã‚¹ã‚«ã‚¦ãƒˆ: åˆå›
```

### KPIãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Portfolio KPIs                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  GitHub Metrics:                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Stars     â”‚   Forks     â”‚  Followers  â”‚   Commits   â”‚ â”‚
â”‚  â”‚    100+     â”‚    20+      â”‚    50+      â”‚   500+/yr   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                             â”‚
â”‚  Content Metrics:                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Repos     â”‚   Blogs     â”‚   Tweets    â”‚   LinkedIn  â”‚ â”‚
â”‚  â”‚     6       â”‚    12/yr    â”‚   52/yr     â”‚   12/yr     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                             â”‚
â”‚  Engagement Metrics:                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Issues    â”‚    PRs      â”‚  Discussionsâ”‚   Scouts    â”‚ â”‚
â”‚  â”‚   Resolved  â”‚   Merged    â”‚   Active    â”‚   Received  â”‚ â”‚
â”‚  â”‚    20+      â”‚    5+       â”‚    10+      â”‚    3+       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ å„ªå…ˆé †ä½ã¾ã¨ã‚

### ä»Šæ—¥ã‚„ã‚‹ã“ã¨ (Day 1)

1. âœ… Profile READMEä½œæˆãƒ»å…¬é–‹
2. âœ… enterprise-rag-system ãƒªãƒã‚¸ãƒˆãƒªä½œæˆ
3. âœ… READMEã¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚’é…ç½®
4. âœ… Pinned Repositoriesã«è¿½åŠ 

### ä»Šé€±ã‚„ã‚‹ã“ã¨ (Week 1)

1. RAG Systemã®åŸºæœ¬å®Ÿè£…é–‹å§‹
   - app/main.py
   - app/core/retriever.py
   - app/api/routes/query.py
2. ãƒ‡ãƒ¢GIFä½œæˆ
3. Twitter/LinkedInæŠ•ç¨¿

### ä»Šæœˆã‚„ã‚‹ã“ã¨ (Month 1)

1. RAG Systemå®Œæˆ
2. Agent Frameworké–‹å§‹
3. ãƒ–ãƒ­ã‚°è¨˜äº‹2æœ¬åŸ·ç­†
4. Pinned Repositoriesã‚’6ã¤åŸ‹ã‚ã‚‹

---

## ğŸ†˜ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### Q: Profile READMEãŒè¡¨ç¤ºã•ã‚Œãªã„

```text
åŸå› : ãƒªãƒã‚¸ãƒˆãƒªåãŒãƒ¦ãƒ¼ã‚¶ãƒ¼åã¨ä¸€è‡´ã—ã¦ã„ãªã„

è§£æ±ºç­–:
1. ãƒªãƒã‚¸ãƒˆãƒªåã‚’ç¢ºèª (å¤§æ–‡å­—å°æ–‡å­—ã‚‚ä¸€è‡´ã•ã›ã‚‹)
2. ãƒªãƒã‚¸ãƒˆãƒªãŒPublicã«ãªã£ã¦ã„ã‚‹ã‹ç¢ºèª
3. README.mdãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
4. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ (Ctrl+Shift+R)
```

### Q: GitHubãƒãƒƒã‚¸ãŒè¡¨ç¤ºã•ã‚Œãªã„

```text
åŸå› : URLã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å/ãƒªãƒã‚¸ãƒˆãƒªåãŒé–“é•ã£ã¦ã„ã‚‹

è§£æ±ºç­–:
1. shields.ioã®URLã‚’ç¢ºèª
2. ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¨ãƒªãƒã‚¸ãƒˆãƒªåãŒæ­£ç¢ºã‹ç¢ºèª
3. ãƒªãƒã‚¸ãƒˆãƒªãŒPublicã‹ç¢ºèª
4. æ•°åˆ†å¾…ã£ã¦ãƒªãƒ­ãƒ¼ãƒ‰
```

### Q: GitHub ActionsãŒå‹•ã‹ãªã„

```text
åŸå› : ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã¾ãŸã¯æ¨©é™ä¸è¶³

è§£æ±ºç­–:
1. Settings â†’ Actions â†’ "Allow all actions" ã‚’ç¢ºèª
2. YAMLã®æ§‹æ–‡ã‚’ãƒã‚§ãƒƒã‚¯ (ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆæ³¨æ„)
3. Actions ã‚¿ãƒ–ã§ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ç¢ºèª
4. secrets ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
```

### Q: Docker ComposeãŒèµ·å‹•ã—ãªã„

```text
åŸå› : ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„

è§£æ±ºç­–:
1. .env ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
2. .env.example ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ .env ã‚’ä½œæˆ
3. å¿…è¦ãªAPIã‚­ãƒ¼ã‚’è¨­å®š
4. docker-compose down && docker-compose up -d
```

### Q: Pineconeã«æ¥ç¶šã§ããªã„

```text
åŸå› : APIã‚­ãƒ¼ã¾ãŸã¯ç’°å¢ƒè¨­å®šãŒé–“é•ã£ã¦ã„ã‚‹

è§£æ±ºç­–:
1. PINECONE_API_KEY ãŒæ­£ã—ã„ã‹ç¢ºèª
2. PINECONE_ENVIRONMENT ãŒæ­£ã—ã„ã‹ç¢ºèª
3. Pineconeãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
4. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèª
```

---

## ğŸ“š å‚è€ƒãƒªã‚½ãƒ¼ã‚¹

### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ»ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«

- [GitHub Profile README Generator](https://rahuldkjain.github.io/gh-profile-readme-generator/)
- [Shields.io](https://shields.io/) - ãƒãƒƒã‚¸ç”Ÿæˆ
- [GitHub Readme Stats](https://github.com/anuraghazra/github-readme-stats)
- [Awesome GitHub Profile README](https://github.com/abhisheknaiidu/awesome-github-profile-readme)

### æŠ€è¡“ãƒªã‚½ãƒ¼ã‚¹

- [LangChain Documentation](https://python.langchain.com/docs/)
- [Pinecone Documentation](https://docs.pinecone.io/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Streamlit Documentation](https://docs.streamlit.io/)

### ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£

- [LangChain Discord](https://discord.gg/langchain)
- [Pinecone Community](https://community.pinecone.io/)
- [r/MachineLearning](https://reddit.com/r/MachineLearning)
- [AI Twitter Community](https://twitter.com/i/communities)

---

## ğŸ‰ å®Œæˆã‚¤ãƒ¡ãƒ¼ã‚¸

**3ãƒ¶æœˆå¾Œã®ã‚ãªãŸã®GitHubãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«:**

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚  âœ¨ é­…åŠ›çš„ãªProfile README                                  â”‚
â”‚     - ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³                              â”‚
â”‚     - Tech Stackãƒãƒƒã‚¸                                      â”‚
â”‚     - GitHub Stats                                          â”‚
â”‚     - Featured Projects                                     â”‚
â”‚                                                             â”‚
â”‚  ğŸ“¦ 6ã¤ã®ãƒ”ãƒ³ç•™ã‚ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ (å…¨ã¦ã‚¹ã‚¿ãƒ¼10+)              â”‚
â”‚     1. enterprise-rag-system â­ 50+                         â”‚
â”‚     2. llm-agent-framework â­ 30+                           â”‚
â”‚     3. realtime-edge-detection â­ 20+                       â”‚
â”‚     4. multilingual-sentiment-analyzer â­ 15+               â”‚
â”‚     5. micro-instruction-engineering â­ 10+                 â”‚
â”‚     6. langchain-google-contributions â­ 10+                â”‚
â”‚                                                             â”‚
â”‚  ğŸŸ¢ ã‚³ãƒŸãƒƒãƒˆæ´»å‹•ã®ç¶™ç¶š (ç·‘ã®ãƒã‚¹)                          â”‚
â”‚     - é€±5+ã‚³ãƒŸãƒƒãƒˆ                                          â”‚
â”‚     - ç¶™ç¶šçš„ãªæ”¹å–„                                          â”‚
â”‚                                                             â”‚
â”‚  â­ åˆè¨ˆ100+ ã‚¹ã‚¿ãƒ¼                                         â”‚
â”‚  ğŸ‘¥ 50+ ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼                                          â”‚
â”‚  ğŸ“ å®šæœŸçš„ãªãƒ–ãƒ­ã‚°æ›´æ–° (æœˆ2æœ¬)                             â”‚
â”‚  ğŸ¤ OSSè²¢çŒ®å®Ÿç¸¾ (LangChainç­‰)                              â”‚
â”‚  ğŸ’¼ ä¼æ¥­ã‹ã‚‰ã®ã‚¹ã‚«ã‚¦ãƒˆè¤‡æ•°                                  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**çµæœ:** re:shineã‚„ä»–ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã€Œã“ã®äººã‚’æ¡ç”¨ã—ãŸã„!ã€ã¨æ€ã‚ã‚Œã‚‹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®å®Œæˆ

---

é ‘å¼µã£ã¦ãã ã•ã„! ğŸš€

è³ªå•ãŒã‚ã‚Œã°ã€ã„ã¤ã§ã‚‚èã„ã¦ãã ã•ã„ã€‚
